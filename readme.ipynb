{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvks7Qb+Aad+MsN6fGB7kn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Computer Vision Project \"Common Swiss Birds\"\n","*FHNW - DAS Data Science - HS2022*\n","\n","*Author: Stefan Caminada*\n","\n","## Task\n","It should be possible to classify images of the 10 most common bird species living in Switzerland.\n","\n","## Data Collection / Preprocessing\n","1. the image data was extracted (crawled with selenium) from Google Image Search.\n","2. it was planned to use Object Detecion from OpenCV to get the most accurate image details. Unfortunately, it turned out that 2 different models could not reliably draw bounding boxes around the birds in the images.\n","3. I continued to use CV2 anyway to create image sections with dimension (224, 224), flip them and change brightness and contrast. Intermediate results were always saved.\n","4. to avoid data leakage, training/validation was separated from test/showcase images from the beginning. --> More precisely, the training set does not contain mirrored or otherwise modified versions of the images that are in the test set.\n","5. finally this is how the datasets were created:\n","    - 02_data\\99_dataset_preparation\\train_images (5000 files. is divided into training and validation).\n","    - 02_data\\99_dataset_preparation\\test_images (1222 Files)\n","    - 02_data\\99_dataset_preparation\\showcase_images (30 Files, 3 per class)\n","\n","## \"03_base_model/base_model.ipynb\"\n","A minimal CNN was created to see what could be classified without much effort.\n","\n","## More sophisticated models...\n","The structure of the notebooks is now pretty much the same everywhere.\n","- Imports\n","- Setting up the connection to Google Drive\n","- Import of my own \"utils\" functions\n","- Defining the 10 classes \n","- Loading the Tensorflow batch datasets (training, valid, test and showcase)\n","- Autotune for optimal execution times\n","- Loading the pre-trained model without head\n","- Recompile with new output layers\n","- Make only new layers trainable\n","- Set callbacks to save the best weights during training and earlystopping if validation Accurracy gets worse two times in a row.\n","- Train over maximum 50 epochs\n","- Training and validation history plotting\n","- Make all layers of the model trainable, recompile with changed optimizer and with small learning rate.\n","- Train over a maximum of 50 epochs (did not work with EfficientNetV2L, because it was too big, but in the first round it is already better than anything else...)\n","- trainings and validations - plot history\n","\n","- Reinitialize model\n","- Load stored (best) weights\n","- Evaluate model\n","- Own evaluation (For test set and showcase):\n","    - Predict dataset labels\n","    - Create Classification report on the dataset\n","    - Confusion Matrix\n","- Advanced showcase evaluation:\n","    - Plot all 30 images\n","    - Create Single Prediction of each image and add Grad-Cam Overlay to see which image parts were important for prediction.\n","\n","## Summary\n","**It's amazing how well a small model can perform and how much more it takes to get even better**\n","\n","| Model | Size(weights) | Test accurracy | Pfad(training/evaluation Notebook) |\n","|-------|---------------|----------------|------------------------------------|\n","| BaseModel | 10'923 KB | 0.7193126082420349 | 03_base_model/base_model.ipynb |\n","| ResNet50 | 100'806 KB | 0.9132569432258606 | 04_resnet_50/resnet_50_model.ipynb |\n","| EffcientNetV2L | 467'350 KB | 0.9533551335334778 | 05_efficientNetV2L/efficient_net_v2l_model.ipynb |\n","| MobileNetV3_Minimalistic | 4'435 KB | 0.8862520456314087 | 06_mobileNetV3_mini/mobilenet_v3_mini_model.ipynb |\n","| VGG16 | 59'628 KB | 0.929623544216156 | 07_VGG16/vgg_16_model.ipynb |\n","| custom VGG16 | - | - | Lernt nichts â›· gotta go now |\n"],"metadata":{"id":"dVez55S7oLHR"}}]}